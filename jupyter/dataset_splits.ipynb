{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a5e9fe-64ef-46ce-897a-8df421731c11",
   "metadata": {},
   "source": [
    "# Load processed datasets\n",
    "From datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebc3c51-57ed-406e-af69-4a3f7db47fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cad', 'elsherief2021', 'sbic', 'kennedy2020', 'salminen2018'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "path = '/storage2/mamille3/hegemonic_hate/tmp/processed_datasets.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    hate_datasets = pickle.load(f)\n",
    "hate_datasets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e1c50-6afe-4da8-b3e3-604a5710d728",
   "metadata": {},
   "source": [
    "# Split datasets\n",
    "Output: train, dev and test folds for with-hegemonic and no-hegemonic splits. All splits/folds have 30/70 hate/no-hate ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48cb09e1-db5f-4c3c-aacf-3354ec438267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27494\n",
      "[nan 'other' 'marginalized' 'hegemonic']\n",
      "27159\n",
      "[nan 'other' 'marginalized']\n"
     ]
    }
   ],
   "source": [
    "# for dataset in hate_datasets:\n",
    "\n",
    "# Remove instances with hegemonic labels\n",
    "print(len(hate_datasets['cad']))\n",
    "print(hate_datasets['cad'].group_label.unique())\n",
    "no_hegemonic = hate_datasets['cad'].query('group_label != \"hegemonic\"')\n",
    "print(len(no_hegemonic))\n",
    "print(no_hegemonic.group_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa07aa09-32ab-4d81-aced-54df8ebfb35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    9081\n",
      "True     3892\n",
      "Name: hate, dtype: int64\n",
      "False    0.699992\n",
      "True     0.300008\n",
      "Name: hate, dtype: float64\n",
      "marginalized    2356\n",
      "other           1536\n",
      "Name: group_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{True: 3892, False: 9081}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample to specific ratios of hate/nonhate\n",
    "hate_ratio = 0.3\n",
    "\n",
    "# Original ratios (though have already been lightly processed, which can affect this\n",
    "# print(hate_datasets['cad'].hate.value_counts(normalize=True))\n",
    "# print(hate_datasets['cad'].hate.value_counts())\n",
    "\n",
    "# Desired sampling of non-hate. Keep all hate rows (for no_hegemonic)\n",
    "n_hate = no_hegemonic.hate.sum()\n",
    "n_samples = {\n",
    "    True: n_hate,\n",
    "    False: int((n_hate*(1-hate_ratio))/hate_ratio)\n",
    "}\n",
    "\n",
    "resampled_no_heg = no_hegemonic.groupby('hate').apply(lambda x: x.sample(n_samples[x.name]))\n",
    "resampled_no_heg.index = resampled_no_heg.index.droplevel('hate')\n",
    "resampled_no_heg = resampled_no_heg.sample(frac=1, random_state=9)\n",
    "print(resampled_no_heg.hate.value_counts())\n",
    "print(resampled_no_heg.hate.value_counts(normalize=True))\n",
    "print(resampled_no_heg.group_label.value_counts())\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b81fac9-b510-47ef-9cd5-93b8f199e718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    9081\n",
      "True     3892\n",
      "Name: hate, dtype: int64\n",
      "False    0.699992\n",
      "True     0.300008\n",
      "Name: hate, dtype: float64\n",
      "marginalized    2175\n",
      "other           1409\n",
      "hegemonic        308\n",
      "Name: group_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sample with_hegemonic dataset\n",
    "resampled_with_heg = hate_datasets['cad'].groupby('hate').apply(lambda x: x.sample(n_samples[x.name]))\n",
    "resampled_with_heg.index = resampled_with_heg.index.droplevel('hate')\n",
    "resampled_with_heg = resampled_with_heg.sample(frac=1, random_state=9)\n",
    "print(resampled_with_heg.hate.value_counts())\n",
    "print(resampled_with_heg.hate.value_counts(normalize=True))\n",
    "print(resampled_with_heg.group_label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea901098-5f4d-4bd8-b3cc-8a931b7aacf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with_heg\n",
      "train: 7783 instances\n",
      "marginalized    1344\n",
      "other            850\n",
      "hegemonic        187\n",
      "Name: group_label, dtype: int64\n",
      "\n",
      "dev: 2595 instances\n",
      "marginalized    438\n",
      "other           274\n",
      "hegemonic        66\n",
      "Name: group_label, dtype: int64\n",
      "\n",
      "test: 2595 instances\n",
      "marginalized    393\n",
      "other           285\n",
      "hegemonic        55\n",
      "Name: group_label, dtype: int64\n",
      "\n",
      "\n",
      "no_heg\n",
      "train: 7783 instances\n",
      "marginalized    1459\n",
      "other            922\n",
      "Name: group_label, dtype: int64\n",
      "dev: 2595 instances\n",
      "marginalized    466\n",
      "other           312\n",
      "Name: group_label, dtype: int64\n",
      "test: 2595 instances\n",
      "marginalized    431\n",
      "other           302\n",
      "Name: group_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split into train/dev/test 60/20/20\n",
    "import numpy as np\n",
    "\n",
    "with_heg, no_heg = {}, {}\n",
    "with_heg['train'], with_heg['dev'], with_heg['test'] = np.split(resampled_with_heg, [int(0.6*len(resampled_with_heg)), int(0.8*len(resampled_with_heg))])\n",
    "no_heg['train'], no_heg['dev'], no_heg['test'] = np.split(resampled_no_heg, [int(0.6*len(resampled_no_heg)), int(0.8*len(resampled_no_heg))])\n",
    "\n",
    "print('with_heg')\n",
    "for name, fold in with_heg.items():\n",
    "    print(f'{name}: {len(fold)} instances')\n",
    "    print(fold.group_label.value_counts())\n",
    "    print()\n",
    "print()\n",
    "print('no_heg')\n",
    "for name, fold in no_heg.items():\n",
    "    print(f'{name}: {len(fold)} instances')\n",
    "    print(fold.group_label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d68b7b74-b583-4644-9432-8e19554d0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out\n",
    "# Just do /tmp for now, but when I settle on which splits are important, then save out to csvs in hate_speech/<dataset>\n",
    "dataset = 'cad'\n",
    "outpath = f'/storage2/mamille3/hegemonic_hate/tmp/{dataset}_hegsplits_{hate_ratio}hate.pkl'\n",
    "with open(outpath, 'wb') as f:\n",
    "    pickle.dump({'with_heg': resampled_with_heg, 'no_heg': resampled_no_heg}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
