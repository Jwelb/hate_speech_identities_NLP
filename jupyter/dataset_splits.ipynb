{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a5e9fe-64ef-46ce-897a-8df421731c11",
   "metadata": {},
   "source": [
    "# Load processed datasets\n",
    "From datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eebc3c51-57ed-406e-af69-4a3f7db47fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cad', 'elsherief2021', 'sbic', 'kennedy2020', 'salminen2018'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "path = '/storage2/mamille3/hegemonic_hate/tmp/processed_datasets.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    hate_datasets = pickle.load(f)\n",
    "hate_datasets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e1c50-6afe-4da8-b3e3-604a5710d728",
   "metadata": {},
   "source": [
    "# Split datasets\n",
    "Output: train, dev and test folds for with-hegemonic and no-hegemonic splits. All splits/folds have 30/70 hate/no-hate ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "298f0c66-cb38-445c-a2fe-7a7fc5c8e9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.733706\n",
       "False    0.266294\n",
       "Name: hate, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_datasets['salminen2018'].hate.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58540618-0c07-494e-a181-8da8a4bcaf42",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cad\n",
      "with_heg\n",
      "train: 7783 instances\n",
      "marginalized    1299\n",
      "other            874\n",
      "hegemonic        208\n",
      "Name: group_label, dtype: int64\n",
      "False    0.694077\n",
      "True     0.305923\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "dev: 1298 instances\n",
      "marginalized    213\n",
      "other           154\n",
      "hegemonic        38\n",
      "Name: group_label, dtype: int64\n",
      "False    0.687982\n",
      "True     0.312018\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "test: 3892 instances\n",
      "marginalized    633\n",
      "other           384\n",
      "hegemonic        89\n",
      "Name: group_label, dtype: int64\n",
      "False    0.715827\n",
      "True     0.284173\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "********************************************\n",
      "elsherief2021\n",
      "with_heg\n",
      "train: 10395 instances\n",
      "marginalized    1903\n",
      "hegemonic        694\n",
      "other            532\n",
      "Name: group_label, dtype: int64\n",
      "False    0.69899\n",
      "True     0.30101\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "dev: 1733 instances\n",
      "marginalized    305\n",
      "hegemonic       117\n",
      "other            78\n",
      "Name: group_label, dtype: int64\n",
      "False    0.710906\n",
      "True     0.289094\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "test: 5198 instances\n",
      "marginalized    942\n",
      "hegemonic       350\n",
      "other           276\n",
      "Name: group_label, dtype: int64\n",
      "False    0.698346\n",
      "True     0.301654\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "********************************************\n",
      "kennedy2020\n",
      "with_heg\n",
      "train: 73357 instances\n",
      "marginalized    48196\n",
      "hegemonic       15867\n",
      "other            5845\n",
      "Name: group_label, dtype: int64\n",
      "False    0.699347\n",
      "True     0.300653\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "dev: 12227 instances\n",
      "marginalized    8035\n",
      "hegemonic       2598\n",
      "other            978\n",
      "Name: group_label, dtype: int64\n",
      "False    0.701889\n",
      "True     0.298111\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "test: 36679 instances\n",
      "marginalized    24154\n",
      "hegemonic        7842\n",
      "other            2967\n",
      "Name: group_label, dtype: int64\n",
      "False    0.700673\n",
      "True     0.299327\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "********************************************\n",
      "salminen2018\n",
      "with_heg\n",
      "train: 3739 instances\n",
      "other           595\n",
      "hegemonic       301\n",
      "marginalized    220\n",
      "Name: group_label, dtype: int64\n",
      "False    0.701524\n",
      "True     0.298476\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "dev: 624 instances\n",
      "other           108\n",
      "hegemonic        49\n",
      "marginalized     26\n",
      "Name: group_label, dtype: int64\n",
      "False    0.706731\n",
      "True     0.293269\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "test: 1870 instances\n",
      "other           321\n",
      "hegemonic       144\n",
      "marginalized    105\n",
      "Name: group_label, dtype: int64\n",
      "False    0.694652\n",
      "True     0.305348\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "********************************************\n",
      "sbic\n",
      "with_heg\n",
      "train: 40995 instances\n",
      "marginalized    7989\n",
      "other           1555\n",
      "hegemonic        340\n",
      "Name: group_label, dtype: int64\n",
      "False    0.698329\n",
      "True     0.301671\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "dev: 6833 instances\n",
      "marginalized    1308\n",
      "other            269\n",
      "hegemonic         55\n",
      "Name: group_label, dtype: int64\n",
      "False    0.697644\n",
      "True     0.302356\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "test: 20498 instances\n",
      "marginalized    3798\n",
      "other            825\n",
      "hegemonic        128\n",
      "Name: group_label, dtype: int64\n",
      "False    0.704117\n",
      "True     0.295883\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "********************************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "# for dataset in sorted(hate_datasets)[4:5]:\n",
    "for dataset in sorted(hate_datasets):\n",
    "    print(dataset)\n",
    "\n",
    "    # Remove instances with hegemonic labels\n",
    "    # print(len(hate_datasets[dataset]))\n",
    "    # print(hate_datasets[dataset].group_label.unique())\n",
    "    no_hegemonic = hate_datasets[dataset].query('group_label != \"hegemonic\"')\n",
    "    # print(len(no_hegemonic))\n",
    "    # print(no_hegemonic.group_label.unique())\n",
    "\n",
    "    # Sample to specific ratios of hate/nonhate\n",
    "    hate_ratio = 0.30 # have to upsample nonhate from Kennedy+2020 if <0.3 and from Salminen+2018 if <0.7ish\n",
    "\n",
    "    # Desired sampling of non-hate. Keep all hate rows (for no_hegemonic)\n",
    "    n_hate = no_hegemonic.hate.sum()\n",
    "    # print(n_hate)\n",
    "    n_samples = {\n",
    "        True: n_hate,\n",
    "        False: int((n_hate*(1-hate_ratio))/hate_ratio)\n",
    "    }\n",
    "    # print(n_samples)\n",
    "    # print(no_hegemonic.hate.value_counts())\n",
    "    \n",
    "    def get_n_samples(x):\n",
    "        \"\"\" Get number of samples for a dataset split \"\"\"\n",
    "        desired_n = n_samples[x.name]\n",
    "        if desired_n > sum(x.hate==x.name):\n",
    "            return x.sample(desired_n, replace=True) # upsample nonhate\n",
    "        else:\n",
    "            return x.sample(desired_n, replace=False)\n",
    "\n",
    "    resampled_no_heg = no_hegemonic.groupby('hate').apply(get_n_samples)\n",
    "    resampled_no_heg.index = resampled_no_heg.index.droplevel('hate')\n",
    "    resampled_no_heg = resampled_no_heg.sample(frac=1, random_state=9)\n",
    "    # print(resampled_no_heg.hate.value_counts())\n",
    "    # print(resampled_no_heg.hate.value_counts(normalize=True))\n",
    "    # print(resampled_no_heg.group_label.value_counts())\n",
    "    # n_samples\n",
    "\n",
    "    # Sample with_hegemonic dataset\n",
    "    # Want to preserve all the hegemonic hate instances so take them out first, then add them back in\n",
    "    hegemonic_hate = hate_datasets[dataset].query('hate and group_label==\"hegemonic\"')\n",
    "    n_samples[True] = n_hate-len(hegemonic_hate)\n",
    "    no_hegemonic_hate = hate_datasets[dataset].query('not (hate and group_label==\"hegemonic\")')\n",
    "    # resampled_with_heg = no_hegemonic_hate.groupby('hate').apply(lambda x: x.sample(n_samples[x.name]))\n",
    "    resampled_with_heg = no_hegemonic_hate.groupby('hate').apply(get_n_samples)\n",
    "    resampled_with_heg.index = resampled_with_heg.index.droplevel('hate')\n",
    "    resampled_with_heg = pd.concat([resampled_with_heg, hegemonic_hate], axis=0) # add hegemonic back in\n",
    "    resampled_with_heg = resampled_with_heg.sample(frac=1, random_state=9)\n",
    "    # print(resampled_with_heg.hate.value_counts())\n",
    "    # print(resampled_with_heg.hate.value_counts(normalize=True))\n",
    "    # print(resampled_with_heg.group_label.value_counts())\n",
    "\n",
    "    # Split into train/dev/test 60/10/30\n",
    "    import numpy as np\n",
    "\n",
    "    with_heg, no_heg = {}, {}\n",
    "    with_heg['train'], with_heg['dev'], with_heg['test'] = np.split(resampled_with_heg, [int(0.6*len(resampled_with_heg)), int(0.7*len(resampled_with_heg))])\n",
    "    no_heg['train'], no_heg['dev'], no_heg['test'] = np.split(resampled_no_heg, [int(0.6*len(resampled_no_heg)), int(0.7*len(resampled_no_heg))])\n",
    "\n",
    "    print('with_heg')\n",
    "    for name, fold in with_heg.items():\n",
    "        print(f'{name}: {len(fold)} instances')\n",
    "        print(fold.group_label.value_counts())\n",
    "        print(fold.hate.value_counts(normalize=True))\n",
    "        # Test hate ratio\n",
    "        print()\n",
    "    # print('no_heg')\n",
    "    # for name, fold in no_heg.items():\n",
    "    #     print(f'{name}: {len(fold)} instances')\n",
    "    #     print(fold.group_label.value_counts())\n",
    "    \n",
    "    print('********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d68b7b74-b583-4644-9432-8e19554d0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out\n",
    "# Just do /tmp for now, but when I settle on which splits are important, then save out to csvs in hate_speech/<dataset>\n",
    "for dataset in hate_datasets:\n",
    "    outpath = f'/storage2/mamille3/hegemonic_hate/tmp/{dataset}_hegsplits_{hate_ratio}hate.pkl'\n",
    "    with open(outpath, 'wb') as f:\n",
    "        pickle.dump({'with_heg': resampled_with_heg, 'no_heg': resampled_no_heg}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
